# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  file {
        type => "log"
        path => "/export/Logs/logstash/*.log"
        start_position => "beginning"
  }
}


filter {

  grok {
    match => 
      { "message" => '%{IPORHOST:clientip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:logdate}\] "%{IPORHOST:http_x_forwarded_for}" "%{IPORHOST:http_j_forwarded_for}" "%{WORD:method} %{DATA:request} HTTP/%{NUMBER:httpversion}" %{NUMBER:response:int} (?:-|%{NUMBER:bytes:int}) %{QS:referrer} %{QS:agent} %{QS:gzip_ratio} "%{IPORHOST:host_name}" "%{IPORHOST:http_x_original_to}"' }
  }

  ruby {
    code => "event.set('ctime', event.get('@timestamp').time.localtime + 8*60*60)"
  }
  ruby {
    code => "event.set('@timestamp',event.get('ctime'))"
  }


  #删除无用字段
  mutate {    
    remove_field => "message"    
    remove_field => "@timestamp"
    remove_field => "@version"
  }


  #mutate{
  #  # 添加字段 product:legend
  #  add_field => { "product" => "legend" }
  #}

}

output {
  if "_grokparsefailure" not in [tags]{

    #在控制台调试的时候使用
    stdout {
      codec => rubydebug
    }
    
    #grop 解析成功的时候写入ES
    elasticsearch {
     codec => "json"   # 导出格式为json
      hosts => ["192.168.182.11:20019"]
      index => "fwd_index_two"
      ## user => "xxxx"
      ## password => "xxxxxx"
    }

  }else{

    #stdout {
    #  codec => rubydebug
    #}
    
    #转换失败的日志就不做处理
    file {
            path => "/export/Logs/grokparsefailure.log"
            codec => line { format => "custom format: %{message}"}
      }
  }

}
